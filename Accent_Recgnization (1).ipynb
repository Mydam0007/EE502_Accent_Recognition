{"cells":[{"cell_type":"markdown","metadata":{"id":"QoctFGvzXoPV"},"source":["## **Importing Libraries**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"k6Su2JiKL_1n","outputId":"525b5d13-1d6a-4455-8e33-c11f40bbed11"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Requirement already satisfied: ffmpeg in /usr/local/lib/python3.10/dist-packages (1.4)\n","Requirement already satisfied: noisereduce in /usr/local/lib/python3.10/dist-packages (3.0.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.13.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (3.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.26.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.66.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.4.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n","Requirement already satisfied: hmmlearn in /usr/local/lib/python3.10/dist-packages (0.3.3)\n","Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.26.4)\n","Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.5.2)\n","Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n"]}],"source":["#Installing the required packages\n","!pip install librosa\n","!pip install keras\n","!pip install tensorflow\n","!pip install ffmpeg\n","!pip install noisereduce\n","!pip install hmmlearn\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_MgrspRjV7m"},"outputs":[],"source":["#Importing the required libraries\n","import os\n","import glob\n","import librosa\n","import librosa.display\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.io import wavfile\n","from scipy import fftpack\n","from scipy.stats import kurtosis,skew,mode\n","import sklearn.preprocessing,sklearn.decomposition\n","from sklearn.metrics import accuracy_score,confusion_matrix\n","from sklearn.utils import shuffle\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import svm\n","from sklearn.naive_bayes import MultinomialNB,GaussianNB\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedShuffleSplit,StratifiedKFold,train_test_split\n","from keras import utils\n","import keras\n","from keras import layers\n","from keras.layers import Activation, Dense, Dropout, Conv1D, Conv2D, Flatten,Reshape, BatchNormalization, ZeroPadding2D,MaxPooling1D,AveragePooling1D, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n","from keras.models import Sequential\n","from keras import regularizers,optimizers\n","from tensorflow.keras.optimizers import SGD,Adam\n","from tensorflow.keras.utils import to_categorical\n","import keras.backend as K\n","from keras.models import load_model\n","from keras.callbacks import EarlyStopping\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"LbiL9HJEv6wt"},"source":["## **Google Drive Link: https://drive.google.com/drive/folders/1rqxai0B95AHMcaJUUfA2CHMF5bCwHPr2?usp=sharing**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Wkq1LZyAL0A","outputId":"6362a43c-b581-4684-bd7f-dc32daf300ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmCHQytN-cLa","outputId":"0b52b05d-c7c9-4261-d555-d0fc6e9cff04"},"outputs":[{"output_type":"stream","name":"stdout","text":["['train.tsv', 'test.tsv', 'clips', 'train_extracted', 'test_extracted', 'train_extracted_denoised', 'test_extracted_denoised']\n"]}],"source":["import os\n","print(os.listdir('/content/drive/MyDrive/HW5_Dataset-main/HW5_Dataset-main/en'))\n"]},{"cell_type":"markdown","metadata":{"id":"lL6voiWiYEb4"},"source":["## **Extracting Training Data from Common Voice. Saves the processed audio files in numpy format**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8gjbD0TEL03"},"outputs":[],"source":["# Function to extract the training data for Common Voice\n","def get_training(original_path):\n","\n","    df = pd.read_csv(os.path.join(original_path, 'train.tsv'), sep='\\t')\n","\n","    # Creating a folder to store the Numpy arrays\n","    extracted_path = os.path.join(original_path, 'train_extracted')\n","    if not os.path.exists(extracted_path):\n","        os.makedirs(extracted_path)\n","\n","    # Getting the file names of audios from the dataframe\n","    audio_files = np.array(df['path'])\n","\n","    # Loading each audio file and save it as a numpy array\n","    for i, audio_file in enumerate(audio_files):\n","        audio_path = os.path.join(original_path, 'clips', audio_file)\n","        d, r = librosa.load(audio_path, mono=True)\n","\n","        # Saving the audio as a numpy array with the same filename (but with .npy extension)\n","        np.save(os.path.join(extracted_path, audio_file.replace('.mp3', '.npy')), d)\n","\n","        if i % 1000 == 0:\n","            print(f'Processed {i}/{len(audio_files)} files')\n","\n","get_training(r'/content/drive/MyDrive/HW5_Dataset-main/HW5_Dataset-main/en')"]},{"cell_type":"markdown","metadata":{"id":"WI14BTKVYSLr"},"source":["## **Extracting Testing Data from Common Voice. Saves the processed audio files in numpy format**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WScU_sGtcAfj"},"outputs":[],"source":["# Function to extract the testing data for Common Voice\n","def get_testing(original_path):\n","\n","    df = pd.read_csv(os.path.join(original_path, 'test.tsv'), sep='\\t')\n","\n","    # Creating a folder to store the Numpy arrays\n","    extracted_path = os.path.join(original_path, 'test_extracted')\n","    if not os.path.exists(extracted_path):\n","        os.makedirs(extracted_path)\n","\n","    # Getting the file names of audios from the dataframe\n","    audio_files = np.array(df['path'])\n","\n","    # Loading each audio file and save it as a numpy array\n","    for i, audio_file in enumerate(audio_files):\n","        audio_path = os.path.join(original_path, 'clips', audio_file)\n","        d, r = librosa.load(audio_path, mono=True)\n","\n","        # Saving the audio as a numpy array with the same filename (but with .npy extension)\n","        np.save(os.path.join(extracted_path, audio_file.replace('.mp3', '.npy')), d)\n","\n","        if i % 1000 == 0:\n","            print(f'Processed {i}/{len(audio_files)} files')\n","\n","get_testing(r'/content/drive/MyDrive/HW5_Dataset-main/HW5_Dataset-main/en')\n"]},{"cell_type":"markdown","metadata":{"id":"tE8e35hgYnwy"},"source":["## **Extracting MFCC Features**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RCkWGUCNYpvY"},"outputs":[],"source":["# Function to extract MFCC features which takes a CSV file and the extracted folder as arguments\n","def get_mfcc_features(original_path, csv_file, extracted_folder):\n","    # Loading the CSV file into a dataframe.\n","    df = pd.read_csv(os.path.join(original_path, csv_file), sep='\\t')\n","\n","    # Get the audio file names from the 'path' column.\n","    audio_extracted = np.array(df['path'])\n","    labels = np.array(df['accents'])\n","\n","    # Creating an empty list to store the features.\n","    mfcc_features = []\n","\n","    # Looping on each audio file path.\n","    for i in range(len(audio_extracted)):\n","        audio_file_data = np.load(os.path.join(original_path, extracted_folder, audio_extracted[i].replace('.mp3', '.npy')))\n","\n","        # Calculating MFCC coefficients for the audio sequence.\n","        mfcc_data = librosa.feature.mfcc(y=audio_file_data, sr=22050, n_fft=441, hop_length=220)\n","\n","        # Calculating various statistical measures on the coefficients.\n","        mean_mfcc = np.mean(mfcc_data, axis=1)\n","        median_mfcc = np.median(mfcc_data, axis=1)\n","        std_mfcc = np.std(mfcc_data, axis=1)\n","        skew_mfcc = skew(mfcc_data, axis=1)\n","        kurt_mfcc = kurtosis(mfcc_data, axis=1)\n","        maximum_mfcc = np.amax(mfcc_data, axis=1)\n","        minimum_mfcc = np.amin(mfcc_data, axis=1)\n","\n","        # Concatenating all the statistical measures and adding to the feature list.\n","        feature_vector = np.concatenate((mean_mfcc, median_mfcc, std_mfcc, skew_mfcc, kurt_mfcc, maximum_mfcc, minimum_mfcc))\n","        mfcc_features.append(feature_vector)\n","\n","    return np.array(mfcc_features), labels\n","\n","mfcc_features = get_mfcc_features(original_path=r'/content/drive/MyDrive/HW5_Dataset-main/HW5_Dataset-main/en', csv_file='train.tsv', extracted_folder='train_extracted')\n"]},{"cell_type":"markdown","metadata":{"id":"C-bFSRE7SlkS"},"source":["## **Printing Out MFCC Features**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQsTv8APSlkS","outputId":"5374900c-bb8e-479e-dd9e-ce67a699fb9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","[[-395.44125    82.187065   23.269756 ...  -32.778545  -59.210373\n","   -19.197433]\n"," [-413.54953    85.24704    12.00551  ...  -31.131939  -51.434082\n","   -24.725624]\n"," [-455.73132   114.03998    18.569351 ...  -35.483437  -31.239515\n","   -32.562225]\n"," ...\n"," [-539.7993     89.63088   -12.189858 ...  -49.5084    -41.546036\n","   -44.69294 ]\n"," [-520.63873    83.46228   -10.559923 ...  -42.985275  -32.64163\n","   -36.955837]\n"," [-493.47556   101.157814  -10.478767 ...  -47.128277  -44.514133\n","   -35.5579  ]]\n"]}],"source":["print(len(mfcc_features))  # Checking how many audio files were processed\n","print(mfcc_features[0])    # Checking the features of the first audio file"]},{"cell_type":"markdown","source":["## The Below code helps to identify the different accent classes ('United States English', 'England English', 'German English,Non native speaker'), which will correspond to class labels 0, 1, 2."],"metadata":{"id":"YPqNm8GATW3Z"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","\n","# Define the path and file name\n","original_path = '/content/drive/MyDrive/HW5_Dataset-main/HW5_Dataset-main/en'\n","csv_file = 'train.tsv'\n","\n","# Load the CSV file into a dataframe\n","df = pd.read_csv(os.path.join(original_path, csv_file), sep='\\t')\n","\n","# Check the unique values in the 'accents' column\n","unique_accents = df['accents'].unique()\n","print(unique_accents)"],"metadata":{"id":"n_DjeqcpTTY9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9i39qDD8SlkS"},"source":["## **Training and Evaluating a Random Forest Model on Processed Data**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dvd4ptRSlkT","outputId":"c7497a73-f243-4b49-d571-9520d1fa62d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Class distribution:\n","2    2436\n","0     657\n","1     629\n","Name: count, dtype: int64\n","Accuracy: 0.9879\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.98      0.95      0.97       127\n","           1       1.00      0.99      1.00       111\n","           2       0.99      1.00      0.99       507\n","\n","    accuracy                           0.99       745\n","   macro avg       0.99      0.98      0.98       745\n","weighted avg       0.99      0.99      0.99       745\n","\n","Cross-Validation Scores: [0.76510067 0.97315436 0.98521505 0.98655914 0.93010753]\n","Average Cross-Validation Score: 0.9280\n"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import librosa\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.model_selection import train_test_split, cross_val_score  # Added the missing import\n","from sklearn.preprocessing import LabelEncoder\n","import matplotlib.pyplot as plt\n","\n","# Extracting features and labels from the dataset using the get_mfcc_features function\n","X, y = get_mfcc_features(original_path, csv_file, extracted_folder)\n","\n","# Encoding the labels as integers (Random Forest requires numeric labels)\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Checking the distribution of the classes in the encoded labels\n","print(f\"Class distribution:\\n{pd.Series(y_encoded).value_counts()}\")\n","\n","# Splitting the data into training and testing sets (80% for training, 20% for testing)\n","X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n","\n","# Initializing the Random Forest classifier with balanced class weights to handle class imbalance\n","rf_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n","\n","# Training the model using the training data\n","rf_model.fit(X_train, y_train)\n","\n","# Making predictions on the test set\n","y_pred = rf_model.predict(X_test)\n","\n","# Calculating the accuracy of the model on the test set\n","rf_accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {rf_accuracy:.4f}\")\n","\n","# Generating a classification report to evaluate the performance in more detail\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n","\n","# Performing cross-validation to assess the model's performance across different splits of the data\n","cv_scores = cross_val_score(rf_model, X, y_encoded, cv=5)\n","print(f\"Cross-Validation Scores: {cv_scores}\")\n","print(f\"Average Cross-Validation Score: {np.mean(cv_scores):.4f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"A-G_CRJ8Slki"},"source":["## **Training and Evaluating a Decision Tree Model on Processed Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Y2U1b08Slki","outputId":"02e688f1-2f51-4a4c-9f96-5f3790bac84d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Class distribution:\n","2    2436\n","0     657\n","1     629\n","Name: count, dtype: int64\n","Accuracy: 0.9584\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.87      0.92      0.90       127\n","           1       0.98      0.97      0.98       111\n","           2       0.98      0.96      0.97       507\n","\n","    accuracy                           0.96       745\n","   macro avg       0.94      0.95      0.95       745\n","weighted avg       0.96      0.96      0.96       745\n","\n","Cross-Validation Scores: [0.64966443 0.90067114 0.90994624 0.9233871  0.90860215]\n","Average Cross-Validation Score: 0.8585\n"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import librosa\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","import matplotlib.pyplot as plt\n","\n","# Extracting MFCC features and labels from the dataset\n","X, y = get_mfcc_features(original_path, csv_file, extracted_folder)\n","\n","# Encoding labels as integers since Decision Tree needs numeric labels\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Display the class distribution to understand the dataset\n","print(f\"Class distribution:\\n{pd.Series(y_encoded).value_counts()}\")\n","\n","# Splitting data into training and testing sets (80% for training, 20% for testing)\n","X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n","\n","# Initializing and training the Decision Tree model\n","dt_model = DecisionTreeClassifier(random_state=42)\n","dt_model.fit(X_train, y_train)\n","\n","# Making predictions on the test set\n","y_pred = dt_model.predict(X_test)\n","\n","# Evaluating the model's performance using accuracy score\n","dt_accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {dt_accuracy:.4f}\")\n","\n","# Printing the classification report to evaluate the model in detail\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n","\n","# Checking the model's performance using cross-validation\n","cv_scores = cross_val_score(dt_model, X, y_encoded, cv=5)\n","print(f\"Cross-Validation Scores: {cv_scores}\")\n","print(f\"Average Cross-Validation Score: {np.mean(cv_scores):.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"1_2_zZ_bSlkj"},"source":["## **Training and Evaluating a KNN Model on Processed Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43rMschNA5_U","outputId":"0e07f700-be86-42e4-86af-00e7dfc436ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Class distribution:\n","2    2436\n","0     657\n","1     629\n","Name: count, dtype: int64\n","Accuracy on test set: 0.9799\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.94      0.94      0.94       127\n","           1       1.00      0.99      1.00       111\n","           2       0.98      0.99      0.99       507\n","\n","    accuracy                           0.98       745\n","   macro avg       0.98      0.97      0.97       745\n","weighted avg       0.98      0.98      0.98       745\n","\n","Cross-Validation Scores: [0.62818792 0.95302013 0.96505376 0.95833333 0.94489247]\n","Average Cross-Validation Score: 0.8899\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# Extracting the MFCC features and labels from the dataset\n","X, y = get_mfcc_features(original_path, csv_file, extracted_folder)\n","\n","# Encoding the labels into numeric values as KNN requires numeric labels\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Displaying the class distribution to understand the dataset\n","print(f\"Class distribution:\\n{pd.Series(y_encoded).value_counts()}\")\n","\n","# Splitting the data into training and testing sets (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n","\n","# Initializing and training the KNN model with n_neighbors=3\n","knn_model = KNeighborsClassifier(n_neighbors=3)\n","knn_model.fit(X_train, y_train)\n","\n","# Making predictions on the test set\n","y_pred = knn_model.predict(X_test)\n","\n","# Evaluating the performance of the model using accuracy score\n","knn_accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy on test set: {knn_accuracy:.4f}\")\n","\n","# Printing the classification report to evaluate the model's performance in detail\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n","\n","# Checking the model's performance using cross-validation\n","cv_scores = cross_val_score(knn_model, X, y_encoded, cv=5)\n","print(f\"Cross-Validation Scores: {cv_scores}\")\n","print(f\"Average Cross-Validation Score: {np.mean(cv_scores):.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"7aiYIlK3Slkj"},"source":["## **Model's Performance Summary**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"0YtcyVhCSlkj","outputId":"ba134061-7fb4-4580-b355-69495a31eb96"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 Model  Accuracy\n","0        Random Forest  0.987919\n","1        Decision Tree  0.958389\n","2  K-Nearest Neighbors  0.979866"],"text/html":["\n","  <div id=\"df-45e6ab2b-297d-4579-9131-3b635cb63ef6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Random Forest</td>\n","      <td>0.987919</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Decision Tree</td>\n","      <td>0.958389</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>K-Nearest Neighbors</td>\n","      <td>0.979866</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45e6ab2b-297d-4579-9131-3b635cb63ef6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-45e6ab2b-297d-4579-9131-3b635cb63ef6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-45e6ab2b-297d-4579-9131-3b635cb63ef6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d6cc10f0-6227-4169-b528-11183710918f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6cc10f0-6227-4169-b528-11183710918f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d6cc10f0-6227-4169-b528-11183710918f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_349a2317-53ad-4fe6-917d-8d25b948f4de\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_349a2317-53ad-4fe6-917d-8d25b948f4de button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('summary_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"summary_df","summary":"{\n  \"name\": \"summary_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Random Forest\",\n          \"Decision Tree\",\n          \"K-Nearest Neighbors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015265075712959285,\n        \"min\": 0.9583892617449664,\n        \"max\": 0.9879194630872483,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9879194630872483,\n          0.9583892617449664,\n          0.9798657718120806\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":27}],"source":["model_summary = {\n","    'Model': ['Random Forest', 'Decision Tree', 'K-Nearest Neighbors'],\n","    'Accuracy': [rf_accuracy, dt_accuracy, knn_accuracy]\n","}\n","\n","# Create a DataFrame to present the results\n","summary_df = pd.DataFrame(model_summary)\n","\n","# Display the summary\n","summary_df"]},{"cell_type":"markdown","metadata":{"id":"WeNNjp2SEyiE"},"source":["## **Statistical ANOVA Test on MFCC Coefficients**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hhp2rj4p1Jyo","outputId":"530b88fc-d141-4cbd-e6f8-5a2bab415ee3"},"outputs":[{"output_type":"stream","name":"stdout","text":["ANOVA Results on MFCC Coefficients:\n","F-statistic: 180.5076, p-value: 0.0000\n","Significant differences exist in MFCC values across accent classes.\n"]}],"source":["from scipy.stats import f_oneway\n","import pandas as pd\n","import numpy as np\n","\n","# Assuming get_mfcc_features function is defined elsewhere and returns X (MFCCs) and y (labels)\n","X, y = get_mfcc_features(original_path, csv_file, extracted_folder)\n","\n","# Converting features and labels into a DataFrame for easier manipulation\n","df = pd.DataFrame(X)\n","df['label'] = y\n","\n","# Selecting a specific MFCC coefficient to test, e.g., the first coefficient (index 0)\n","mfcc_index = 0\n","grouped_data = [df[df['label'] == label][mfcc_index].values for label in df['label'].unique()]\n","\n","# Performing ANOVA to test differences in means across groups\n","f_stat, p_value = f_oneway(*grouped_data)\n","\n","# Output results\n","print(\"ANOVA Results on MFCC Coefficients:\")\n","print(f\"F-statistic: {f_stat:.4f}, p-value: {p_value:.4f}\")\n","\n","# Interpretation\n","if p_value < 0.05:\n","    print(\"Significant differences exist in MFCC values across accent classes.\")\n","else:\n","    print(\"No significant differences found in MFCC values across accent classes.\")\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}